# Инструменты мониторинга

## Nagios

С конца 1990-х

Популярный инструмент для мониторинга серверов и сетевых устройств, поддерживающий множество плагинов. Сложный в настройке (конфигурация осуществляется через множество текстовых файлов), простой в использовании.

Нужен был для отслеживания состояния оборудования и сервисов, но его фокус был больше на статусах и состояниях, чем на графиках и трендах.

* **Производительность**: Высокая производительность при мониторинге большого количества хостов и сервисов.
* **Удобство поддержки**: Имеет активное сообщество и множество плагинов, но требует времени на настройку.
* **Хранение данных**: Хранит данные в текстовых файлах, что может быть неэффективно для больших объемов. **Нет поддержки баз данных**: Nagios не использует базы данных для хранения информации, что может ограничивать его возможности масштабирования и управления конфигурацией. . Однако для более сложных сценариев можно использовать библиотеку NDO (Nagios Database Output), которая позволяет экспортировать данные в реляционные базы данных, такие как MySQL или PostgreSQL.
* **Отсутствие гибкости**: Не так гибок, как Zabbix, особенно в плане настройки и управления; требует дополнительных плагинов для расширения функциональности.
* **Настраиваемый алертинг**: Позволяет настраивать алерты по различным критериям, но интерфейс может быть не очень интуитивным.

#### Сравнение с Prometheus:

* **Метод сбора данных**: Prometheus использует модель pull для сбора метрик, что позволяет более эффективно управлять динамическими системами, тогда как Nagios полагается на push через плагины.
* **Хранение данных**: Prometheus хранит временные ряды в формате TSDB (Time Series Database), что делает его более подходящим для работы с временными метриками по сравнению с Nagios, который использует RRD (Round Robin Database).
* **Визуализация**: Prometheus часто используется в связке с Grafana для создания дашбордов и визуализации данных, чего не хватает в Nagios.

#### Сравнение с Zabbix:

* **Удобство конфигурации**: Zabbix предлагает веб-интерфейс для настройки и управления, что делает его более удобным в использовании по сравнению с Nagios.
* **Хранение данных**: Zabbix хранит данные в реляционных базах данных, что позволяет быстрее вносить изменения без необходимости перезагрузки системы.
* **Интеграция и расширяемость**: Zabbix имеет встроенные средства визуализации и поддерживает мониторинг логов и JMX из коробки, тогда как Nagios требует дополнительных усилий для достижения аналогичных возможностей.

## Zabbix

С 2000-х

Универсальное решение для мониторинга IT-инфраструктуры, включая серверы, сети, устройства и приложения.

* **Преимущества**:

  - **Широкий функционал**: Поддерживает мониторинг различных показателей, таких как доступность сервисов, состояние приложений и ресурсы системы.

  * **Долгосрочное хранение данных**: Использует реляционные базы данных (MySQL, PostgreSQL) для хранения данных, что позволяет легко хранить и анализировать информацию за длительное время.
  * **Гибкость**: Может интегрироваться с внешними метриками через API и поддерживает множество протоколов (SNMP, IPMI и др.).
  * **Удобный интерфейс**: Предоставляет интуитивно понятный веб-интерфейс для управления и настройки.
* **Недостатки**:

  - **Сложность настройки**: Требует больше времени на первоначальную настройку и конфигурацию по сравнению с Prometheus.

  * **Производительность**: Может испытывать трудности при масштабировании в больших инфраструктурах без использования прокси-серверов.

Zabbix лучше подходит для комплексного мониторинга традиционной IT-инфраструктуры, включая серверы и сети, благодаря своему широкому функционалу и долговременному хранению данных.

Большое количество удобных шаблонов для сбора метрик и алертинга https://git.zabbix.com/projects/ZBX/repos/zabbix/browse/templates

При установке Zabbix агента на новый хост он может автоматически зарегистрироваться на Zabbix сервере (авторегистрация), что упрощает процесс добавления новых узлов в систему мониторинга.

Zabbix агент может собирать данные не только о хостах, но и интегрироваться с другими системами через различные протоколы, такие как SNMP или JMX.

Prometheus, в свою очередь, является отличным выбором для динамических сред и микросервисов, обеспечивая высокую производительность и автоматизацию. Оба инструмента могут использоваться совместно для обеспечения более полного мониторинга: Zabbix может следить за инфраструктурой, а Prometheus — за метриками производительности приложений.

## Prometheus

С 2012

Открытый исходный код, всеядный (десятки экпортёров, но если нужного нет, можно кастомизировать и собирать любые данные самому), поддерживает мощный язык запросов PromQL, что позволяет проводить сложный анализ данных и классно мэтчиться с Grafana

* **Масштабируемость:** инструмент может обрабатывать большие объемы данных и масштабироваться “горизонтально” , что делает его подходящим для сложных и больших сред.
* **Алертинг:** Prometheus содержит конфигурации по оповещениям, которые позволяют определять правила алертинга и нотификации на основе пороговых значений метрик и автоматически уведомлять при возникновении проблем.
* **Многомерная модель данных:** Prometheus использует базу данных типа time-series и хранит все данные в виде метрик, идентифицируемых комбинацией имени метрики и необязательных пар ключ-значение (label). Это обеспечивает гибкий и детальный запрос метрик.
* * **Политика хранения на основе времени:** Данные будут храниться в течение указанного количества дней. По умолчанию данные хранятся 15 дней.
  * **Политика хранения на основе размера:** Вы можете указать максимальный объем данных, который может хранить TSDB. Когда этот лимит будет достигнут, Prometheus освободит место для новых данных.
* **Интеграции с другими системами и инструментами:** Prometheus хорошо интегрируется с другими системами и инструментами, включая Grafana для визуализации, что упрощает создание комплексных панелей мониторинга.
* Работает по pull модели, но может и по push (например, при выполнении пакетных заданий (batch jobs) на Kubernetes CronJob, где задания запускаются на короткий период времени, этот подход может быть неэффективным - тогда нужен **push**, чтобы отправить метрики непосредственно в Prometheus. для этого есть компонент под названием **Pushgateway**  (промежуточный шлюз, который позволяет отправлять метрики от приложений или скриптов, запуcкается как отдельный сервис, отправляет метрики с помощью HTTP API и экспортирует эти метрики по пути `/metrics`, откду их забирает пром. Pushgateway временно хранит метрики в оперативной памяти. Чтобы настроить Prometheus для работы с Pushgateway, необходимо добавить соответствующую конфигурацию в файл `prometheus`)
* Бест практисез: https://sysdig.com/blog/prometheus-exporters-best-practices/

1. **Выбор подходящего exporter**: Существует множество exporters для различных приложений и сервисов. Важно выбирать те, которые активно поддерживаются и обеспечивают нужные метрики. Рекомендуется использовать списки, такие как Exporters and Integrations на сайте Prometheus или PromCat.io, чтобы найти надежные решения.
2. **Понимание метрик**: Каждый exporter предоставляет свои метрики, которые должны быть четко документированы. Важно знать, как правильно использовать **инструментальные метки** (instrumentation labels) для контекстуализации данных и **целевые метки** (target labels) для агрегации метрик.
3. **Настройка значимых алертов**: Алерты должны быть настроены так, чтобы не вызывать усталости у команды поддержки. Необходимо определить ключевые показатели для алертов, основываясь на понимании приложений и их критических элементов.
4. **Доступ к данным для команды**: Важно обеспечить доступ к данным метрик для всей команды через **дашборды**. Рекомендуется создавать общие дашборды вместо индивидуальных, чтобы упростить управление и доступ к информации.
5. **Планирование масштабирования**: С увеличением количества exporters могут возникнуть проблемы с видимостью и хранением данных. Необходимо заранее планировать масштабирование системы, используя решения вроде Thanos или Cortex для долгосрочного хранения данных.

#### МИНУСЫ

- Prometheus по горизонтали нормально не масштабируется.  Имеет ограничения по хранению данных: он в основном работает с временными рядами и не поддерживает долгосрочное хранение без дополнительных решений, таких как Thanos. Чтобы справиться с проблемами масштабирования, вы можете попробовать консолидировать Grafana, развернуть Thanos, Cortex или использовать коммерческое решение, такое как Sysdig.

  https://core247.kz/blog/prometheus-architecture

## Sensu

Гибкое решение для проверки работоспособности телеметрии и служб.

* **Производительность**: Высокая производительность при работе с большим количеством метрик благодаря распределенной архитектуре.
* **Удобство поддержки**: + легко интегрируется с другими инструментами.
* **Оптимизированное хранение данных**: Позволяет использовать различные базы данных для хранения метрик.
* **Настраиваемый алертинг**: Гибкая система оповещений с возможностью настройки условий.


| Инструмент | Оперативная память                                                               | Диск                                                                  | Скорость работы                                                            |
| -------------------- | ------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |
| **Prometheus**       | \~600 Мб для 60,000 метрик                                                             | Зависит от объема собираемых данных        | Высокая; поддерживает параллельные запросы         |
| **Grafana**          | 1-2 Гб (в зависимости от источника)                                      | Не хранит данные самостоятельно               | Зависит от производительности источника              |
| **Nagios**           | 512 Мб - 1 Гб                                                                                 | Хранит данные в текстовых файлах              | Эффективен для небольших/средних инфраструктур |
| **Zabbix**           | Минимум 1 Гб; до 16 Гб для крупных систем                            | Использует реляционные БД (MySQL, PostgreSQL)      | Высокая при правильной настройке                            |
| **Sensu**            | Минимум 1 Гб; рекомендуется больше для крупных систем | Зависит от конфигурации (например, InfluxDB) | Высокая благодаря распределенной архитектуре    |


| Инструмент | Собираемые данные                                                                                                                                                 | От каких сущностей собираются данные                                                                                                    |
| -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Prometheus**       | Временные ряды метрик, такие как CPU, память, сетевой трафик                                                                        | Приложения, контейнеры, сервисы (например, Kubernetes), базы данных                                                        |
| **Zabbix**           | Разнородная информация, включая текстовые значения, состояние оборудования и сетевых устройств | Серверы, сети, оборудование клиентов, SSL-сертификаты, промышленные контроллеры                        |
| **Nagios**           | Состояние сервисов и хостов, производительность систем                                                                            | Серверы, сетевые устройства, приложения через плагины (например, NRPE)                                            |
| **Sensu**            | Метрики производительности и состояния приложений и инфраструктуры                                                    | Серверы, контейнеры, микросервисы; поддерживает интеграцию с различными системами через API |

## С **хранением** в облаках (и три не опенсорс, только Streamdal)

~~### New RelicМногофункциональная платформа для мониторинга производительности приложений и инфраструктуры.**Производительность**: Высокая производительность для мониторинга приложений и инфраструктуры в реальном времени.**Удобство поддержки**: +**Оптимизированное хранение данных**: Использует **ОБЛАЧНОЕ** хранилище для хранения метрик и логов.**Настраиваемый алертинг**: система алертов с множеством настроек и интеграций с другими системами.### DatadogSaaS-платформа для мониторинга серверов, баз данных и облачных приложений.**Производительность**: Высокая производительность при сборе данных из различных источников.**Удобство поддержки**:+**Оптимизированное хранение данных**: Хранит данные в **ОБЛАКЕ**, что обеспечивает масштабируемость.**Настраиваемый алертинг**: + с возможностью настройки по различным параметрам.~~

### Streamdal

Инструмент для наблюдения за данными, помогающий выявлять инциденты с данными.

* **Производительность**: Эффективен для мониторинга потоковых данных в реальном времени.
* **Удобство поддержки**: дока +, сообщество маленькое
* **Оптимизированное хранение данных**: Использует **ОБЛАЧНЫЕ** технологии для хранения данных.
* **Настраиваемый алертинг**: + на основе условий в потоках данных.

~~### StatusPalПлатформа для автоматизации уведомлений об инцидентах.**Производительность**: Хорошая производительность для отслеживания статуса сервисов и приложений.**Удобство поддержки**: +**Оптимизированное хранение данных**: Хранит данные в **ОБЛАКЕ** для быстрого доступа и анализа.**Настраиваемый алертинг**: + о статусе сервисов по различным каналам.~~

# Инструменты логирования

## **ELK Stack** (Elasticsearch, Logstash, Kibana)

С 2015

Мощный, жесть, Elasticsearch - высокая производительность поиска и фильтрации данных, Logstash обрабатывает данные, а Kibana предоставляет широкие возможности визуализации

1. **Logstash**:

Это конвейер обработки данных, который собирает логи из различных источников (например, файлов, API, системных журналов), обрабатывает их с помощью фильтров и отправляет в Elasticsearch. Logstash поддерживает множество входных и выходных плагинов, что позволяет работать с различными форматами данных. Основные фильтры включают grok для парсинга логов, date для обработки временных меток и geoip для добавления геолокации по IP-адресам.

2. **Elasticsearch**:

Это поисковая система, основанная на Apache Lucene, которая обеспечивает хранение и быстрый поиск данных в формате JSON. Elasticsearch является нереляционным хранилищем данных, что позволяет загружать документы без строгой схемы. Он поддерживает горизонтальное масштабирование и репликацию, что делает его подходящим для работы с большими объемами данных.

3. **Kibana**:

Это веб-интерфейс для визуализации данных из Elasticsearch. Kibana позволяет пользователям создавать дашборды, графики и диаграммы на основе собранных логов. Он поддерживает специальный синтаксис запросов (KQL) для фильтрации и анализа данных.

- чумовая сложная настройка ELK-стека, особенно при работе с большими объемами данных
- ест очень много ресурсов (кто вообще себе это может позволить)
- сложно масштабировать
- https://habr.com/ru/articles/594805/

#### Общие требования к ресурсам для Elasticsearch

1. **Память**: Elasticsearch требует значительных объемов оперативной памяти для индексации и хранения данных. Рекомендуется выделять как минимум 50% доступной оперативной памяти для JVM (Java Virtual Machine), что может составлять десятки гигабайт в зависимости от объема данных. В некоторых случаях, для высоконагруженных систем, может потребоваться 16 ГБ и более памяти для обеспечения нормальной работы.
2. **Процессор**: Elasticsearch использует многопоточность для обработки запросов и индексации, поэтому количество ядер процессора также влияет на производительность. Для обработки больших объемов данных может потребоваться от 4 до 16 ядер.
3. **Хранение**: Хранение данных в Elasticsearch также требует значительных ресурсов. Для 60 тысяч метрик с учетом хранения и индексации может понадобиться несколько сотен гигабайт дискового пространства, особенно если данные хранятся в высоком разрешении и требуют частого обновления.

#### Сравнение с Prometheus

* **Prometheus**: Для обработки 60 тысяч метрик достаточно 600 Мб оперативной памяти и 15% одного ядра процессора, что делает его значительно более легковесным решением по сравнению с Elasticsearch.
* **Elasticsearch**: В отличие от Prometheus, который использует pull-модель для сбора метрик, Elasticsearch требует больше ресурсов из-за своей архитектуры хранения и индексации данных.

## **Grafana Loki**

С 2018

Grafana Loki — это система для сбора и анализа логов, запущенная в 2018 году. Она работает по схеме, аналогичной ELK-стеку и Graylog, но с уникальными особенностями.

### Плюсы:

* **Оптимизирован для хранения логов в формате JSON**: Loki эффективно работает с логами, обеспечивая их сжатие и хранение.
* **Простота настройки**: Легко развертывается и настраивается, что делает его доступным для пользователей.
* **Централизованное логирование**: Позволяет собирать и визуализировать логи из различных источников в одном месте, упрощая анализ работы приложений и серверов в реальном времени.
* **Экономия ресурсов**: Индексация только метаданных (тегов) позволяет снизить требования к оперативной памяти и дисковому пространству.
* **Интеграция с Grafana**: Логи визуализируются с использованием языка запросов LogQL, что позволяет создавать дашборды и графики.

### Фичи:

* Loki индексирует только метаданные (теги) логов, а сами логи сжимаются и хранятся в отдельных файлах, что позволяет избежать больших затрат на оперативную память. Это делает невозможным полнотекстовый поиск, но ускоряет обработку за счет параллельного выполнения запросов.**Индексация метаданных**: Индексирует только метаданные логов, что ускоряет обработку данных.
* **Агенты-сборщики**: Основным агентом для Loki является Promtail, который собирает и обрабатывает логи. Promtail может интегрироваться с Kubernetes для автоматического добавления меток на основе метаданных. Другие агенты, такие как Fluentd или Logstash, также могут использоваться.Основной агент Promtail собирает логи и может интегрироваться с Kubernetes для автоматического добавления меток.
* **Визуализация через Grafana**: Логи из Loki визуализируются в Grafana с использованием языка запросов LogQL, который похож на PromQL из Prometheus
* **Система оповещений**: Развита система алертов, позволяющая настраивать уведомления на основе определенных условий.

### Минусы:

* **Ограниченные возможности алертов**: Функциональность алертов может быть ограничена по сравнению с более специализированными решениями для мониторинга.
* **Одной из самых частых проблем является потеря логов при их сборе. Например, когда используется Fluent Bit или другой агент для отправки логов в Loki, иногда они могут перестать отправляться. Это может происходить из-за неправильной настройки буферов или сбоев в работе самого агента. Такие ситуации требуют анализа логов и возможной замены агента на более стабильный, как это было сделано в одном из случаев, когда вместо Fluent Bit был использован VectorПотеря логов**: Возможна потеря логов при сборе из-за неправильной настройки буферов или сбоев в работе агента.

- С увеличением нагрузки на систему могут возникнуть проблемы с производительностью, такие как тайм-ауты при записи логов или дроп логов со стороны ingester и distributor в Loki. Это может привести к тому, что запросы на получение данных будут выполняться слишком долго или вовсе завершаться ошибками. Для решения этой проблемы необходимо тщательно настраивать параметры пропускной способности и тайм-ауты в конфигурации Loki, что требует глубокого понимания системы и её работы (https://habr.com/ru/companies/m2tech/articles/693504/ и https://rtfm.co.ua/ru/grafana-loki-alerty-s-ruler-i-labels-iz-logov)
- При попытке подключения Grafana к Loki могут возникать ошибки 502 (Bad Gateway) и 504 (Gateway Timeout). Эти ошибки возникают, когда Grafana не может получить ответ от Loki. Причины могут быть различными: неправильная настройка URL для подключения к Loki, проблемы с сетевыми настройками или недостаточные ресурсы для обработки запросов. Устранение этих ошибок часто требует проверки конфигурации и увеличения таймаутов в настройках Loki https://grafana.com/docs/loki/latest/operations/troubleshooting

## **Graylog**

C 2009

### Плюсы:

* **Удобный интерфейс и простота использования**: Graylog предлагает интуитивно понятный веб-интерфейс, который облегчает поиск и анализ логов.
* **Поддержка различных форматов данных**: Он может принимать данные из множества источников, поддерживая около 10 встроенных входных плагинов, таких как HTTP, syslog, TCP и UDP.

- Graylog поддерживает множество типов ввода из коробки. На момент написания статьи Graylog поддерживает следующее:

1. Syslog (TCP, UDP, AMQP, Kafka)
2. GELF (TCP, UDP, AMQP, Kafka, HTTP)
3. AWS (AWS Logs, FlowLogs, CloudTrail)
4. Beats/Logstash
5. CEF (TCP, UDP, AMQP, Kafka)
6. JSON Path from HTTP API
7. Netflow (UDP)
8. Простой / не обработанный текст (TCP, UDP, AMQP, Kafka)

* **Гибкая система алертов**: Встроенная система оповещений позволяет настраивать уведомления при выполнении определенных условий, таких как фильтрация по значению поля или превышение порогового значения.

### Фичи:

* **Агрегация логов**: Graylog выполняет функции агрегатора логов и визуализации через одностраничное веб-приложение, что позволяет централизованно собирать и обрабатывать данные.
* **Обработка данных**: Использует экстракторы для извлечения нужных полей из логов с помощью регулярных выражений и шаблонов grok.
* **Интеграция с Elasticsearch**: Обработанные логи отправляются в Elasticsearch для хранения и поиска, что обеспечивает высокую производительность.
* **Использование MongoDB**: Graylog использует MongoDB для хранения конфигураций и настроек, что добавляет гибкости в управлении данными.
* **Search Workflow**: Позволяет создавать комбинированные поисковые запросы и сохранять их результаты на дашборде.

### Минусы:

* **Зависимость от Elasticsearch**: Это может усложнить инфраструктуру и ограничить возможности отчетности по сравнению с ELK-стеком.
* **Требования к ресурсам**: Для эффективной работы Graylog рекомендуется выделять минимум 4 Гб оперативной памяти и 2 CPU, особенно при высокой нагрузке. Также необходимо учитывать ресурсы для Elasticsearch и MongoDB.

### Отличия от ELK-стека:

- Использование MongoDB: Graylog дополнительно использует MongoDB для хранения конфигураций и настроек.
- Search Workflow: Позволяет создавать комбинированные поисковые запросы и сохранять их результаты на дашборде
- Система оповещений: В отличие от ELK, Graylog имеет встроенную систему алертов, которая позволяет настраивать уведомления при выполнении определенных условий. Это может быть фильтрация по значению поля или превышение порогового значения агрегирования.
- Агенты сбора логов:
- Graylog поддерживает установку агентов (Graylog Collector Sidecars) на устройствах для централизованного сбора информации. Это позволяет управлять конфигурациями агентов через веб-интерфейс с использованием тегов для автоматической настройки.

#### Logstash

Logstash — это мощный инструмент из ELK-стека, имеет много фильтров и плагинов (поэтому сложе в настройке). Он поддерживает множество форматов входящих данных, что делает его универсальным решением для сбора логов. Требует значительных ресурсов для эффективной работы, что может увеличить ваши затраты на инфраструктуру.  При высокой нагрузке, например, при обработке 400 ГБ логов в день, его потребление CPU может увеличиваться до 12 ядер. Скорость обработки сообщений может достигать 100,000 сообщений в минуту, но это требует значительных ресурсов. Важно отметить, что Logstash работает на JRuby и имеет один общий цикл обработки, что может привести к проблемам с производительностью при высоких нагрузках. В таких случаях может потребоваться настройка буферизации и использование Redis для сглаживания пиков нагрузки.

#### Fluentd

Fluentd — это гибкий инструмент для сбора логов, имеет много входных и выходных плагинов. Его настройка обычно проще по сравнению с Logstash, что делает его отличным выбором для небольших проектов или команд, которые только начинают работать с логированием. Однако, если у вас большой объем данных, Fluentd может потребовать дополнительных усилий для настройки производительности.

Fluentd также требует ресурсов, но в целом считается более легковесным по сравнению с Logstash.

https://www.educba.com/fluentd-vs-logstash/

#### Sentry

Sentry — это специализированный инструмент для отслеживания ошибок и исключений в приложениях. Не предназначен для централизованного логирования. Он сосредоточен на мониторинге ошибок и не предоставляет полного набора инструментов для отслеживания производительности приложений. Для небольших команд Sentry может работать на стандартных конфигурациях серверов, но при увеличении нагрузки может потребоваться более мощное оборудование.

#### Monq

Monq — это новое решение на рынке, которое поддерживает AIOps и мониторинг состояния сервисов. В бесплатной версии функциональность ограничена, и вам может понадобиться больше времени на тестирование перед внедрением. Важно провести дополнительные испытания перед внедрением, чтобы определить оптимальные ресурсы для вашего окружения.входящий в состав ELK-стека, обладает мощными возможностями обработки данных благодаря фильтрам и плагинам. Он поддерживает множество форматов входящих данных, но может быть сложным в настройке для новичков.


| Инструмент | Простота настройки                                                                                                 | Потребление ресурсов                                                                                                                                                                                   | Основные цели использования                                                                                                                      |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Logstash**         | Сложная настройка; требует времени на конфигурацию                                      | Высокое потребление ресурсов, особенно при обработке больших объемов данных (рекомендуется 4 Гб ОЗУ и более)                    | Сбор, обработка и передача логов; интеграция с ELK-стеком для анализа данных                                  |
| **Fluentd**          | Легче настраивать по сравнению с Logstash; поддерживает множество плагинов | Низкое до умеренного потребление ресурсов; оптимизирован для работы на менее мощных серверах (рекомендуется 1-2 Гб ОЗУ) | Централизованный сбор логов из различных источников; интеграция с системами хранения логов |
| **Sentry**           | Простота настройки и использования; интуитивно понятный интерфейс         | Умеренное потребление ресурсов; зависит от объема обрабатываемых ошибок (рекомендуется 2 Гб ОЗУ)                                         | Отслеживание ошибок и исключений в приложениях; уведомления о проблемах в реальном времени  |
| **Monq**             | Простота настройки, но требует тестирования перед внедрением                   | Низкое до умеренного потребление ресурсов; использует ClickHouse для хранения данных (рекомендуется 2-4 Гб ОЗУ)                         | Полноценный мониторинг и анализ логов; поддержка AIOps и автоматизации                                            |
